import rclpy
import os
import time
from rclpy.node import Node
import pyaudio
import pygame
import wave
import threading
import webrtcvad
import queue
from std_msgs.msg import String, UInt16, Bool
from utils.mic_serial import kws_mic
from utils import large_model_interface
from utils.large_model_interface import rec_wav_music_en
from ament_index_python.packages import get_package_share_directory

class ASRNode(Node):
    def __init__(self):
        super().__init__("asr_node")
        # åˆå§‹åŒ–å‚æ•°ã€å˜é‡ / Initialize parameters and variables
        self.init_param_config()
        # åˆå§‹åŒ–è¯­éŸ³å”¤é†’ / Initialize keyword spotting (KWS)
        self.kws_init()
        # åˆå§‹åŒ–ASRæ¨¡å‹ / Initialize ASR model
        self.asr_mdoel_init()
        # åˆå§‹åŒ–è¯­è¨€è®¾ç½® / Initialize language settings
        self.language_init()
        # åˆå§‹åŒ–ç³»ç»Ÿå£°éŸ³ / Initialize system sound functionality
        self.system_sound_init()
        # åˆå§‹åŒ–ROSé€šä¿¡ / Initialize ROS communication
        self.init_ros_comunication()
        # æ‰“å°åˆå§‹åŒ–ä¿¡æ¯ / Log initialization completion
        self.get_logger().info("asr_node Initialization completed")

    def init_ros_comunication(self):
        # åˆ›å»ºèœ‚é¸£å™¨å‘å¸ƒè€… / Create a publisher for the buzzer
        self.pub_beep = self.create_publisher(UInt16, "beep", 10)
        # åˆ›å»ºASRå‘å¸ƒè€…ï¼Œå‘å¸ƒè½¬æ¢å®Œæˆçš„æ¶ˆæ¯ / Create an ASR publisher to publish conversion results
        self.asr_pub = self.create_publisher(String, "asr", 5)
        # åˆ›å»ºå”¤é†’ä¿¡æ¯å‘å¸ƒè€… / Create a publisher for wake-up signals
        self.wakeup_pub = self.create_publisher(Bool, "wakeup", 5)
        #åˆ›å»ºå‘å¸ƒå½•éŸ³çŠ¶æ€å‘å¸ƒè€… / Create a publisher for recording status
        self.record_status_pub=self.create_publisher(Bool, "record_status", 5)

	
    def init_param_config(self):
        self.user_speechdir = os.path.join(
            get_package_share_directory("largemodel"),
            "resources_file",
            "user_speech.wav",
        )
        # å‚æ•°å£°æ˜ / Declare parameters
        self.declare_parameter("VAD_MODE", 1)
        self.declare_parameter("sample_rate", 48000)
        self.declare_parameter("frame_duration_ms", 30)
        self.declare_parameter("language", "en")
        self.declare_parameter("use_oline_asr", False)
        self.declare_parameter("mic_serial_port", "/dev/ttyUSB1")
        self.declare_parameter("mic_index", 0)
        self.declare_parameter("regional_setting", "international")


        # è·å–æœåŠ¡å™¨å‚æ•° / Get server parameters
        self.VAD_MODE = (
            self.get_parameter("VAD_MODE").get_parameter_value().integer_value
        )
        self.sample_rate = (
            self.get_parameter("sample_rate").get_parameter_value().integer_value
        )
        self.frame_duration_ms = (
            self.get_parameter("frame_duration_ms").get_parameter_value().integer_value
        )
        self.language = (
            self.get_parameter("language").get_parameter_value().string_value
        )
        self.use_oline_asr = (
            self.get_parameter("use_oline_asr").get_parameter_value().bool_value
        )
        self.mic_serial_port = (
            self.get_parameter("mic_serial_port").get_parameter_value().string_value
        )
        self.mic_index = (
            self.get_parameter("mic_index").get_parameter_value().integer_value
        )
        self.regional_setting = (
            self.get_parameter("regional_setting").get_parameter_value().string_value
        )
        self.frame_bytes = int(
            self.sample_rate * self.frame_duration_ms / 1000
        )  # éŸ³é¢‘å¸§å¤§å° / Audio frame size

        # å¤§æ¨¡å‹æ¥å£å®ä¾‹ç«¯ / Instance of the large model interface
        self.modelinterface = large_model_interface.model_interface()
        # åˆå§‹åŒ– WebRTC VAD / Initialize WebRTC VAD
        self.vad = webrtcvad.Vad()
        self.vad.set_mode(self.VAD_MODE)
        self.current_thread = None  # å”¤é†’å¤„ç†çº¿ç¨‹ / Thread for handling wake-up events
        self.stop_event = threading.Event()

    def main_loop(self):
        while rclpy.ok():
            while (
                self.audio_request_queue.qsize() > 1
            ):  # åªå¤„ç†æœ€è¿‘çš„ä¸€æ¬¡å”¤é†’è¯·æ±‚ï¼Œé˜²æ­¢é‡å¤å”¤é†’ / Process only the most recent wake-up request to prevent duplicates
                self.audio_request_queue.get()

            if not self.audio_request_queue.empty():
                self.audio_request_queue.get()
                self.wakeup_pub.publish(
                    Bool(data=True)
                )  # å‘å¸ƒå”¤é†’ä¿¡å· / Publish wake-up signal
                self.get_logger().info("I'm here")
                self.play_audio(self.audio_dict[self.first_response])
                if (
                    self.current_thread and self.current_thread.is_alive()
                ):  # æ‰“æ–­ä¸Šæ¬¡çš„å”¤é†’å¤„ç†çº¿ç¨‹ / Interrupt the previous wake-up handling thread
                    self.stop_event.set()
                    self.current_thread.join()  # ç­‰å¾…å½“å‰çº¿ç¨‹ç»“æŸ / Wait for the current thread to finish
                    self.stop_event.clear()  # æ¸…é™¤äº‹ä»¶ / Clear the event
                self.current_thread = threading.Thread(target=self.kws_handler)
                self.current_thread.daemon = True
                self.current_thread.start()
            rclpy.spin_once(self, timeout_sec=0.1)
            time.sleep(0.1)

    def kws_handler(self) -> None:
        if self.stop_event.is_set():
            return

        if self.listen_for_speech(self.mic_index):
            asr_text = self.ASR_conversion(
                self.user_speechdir
            )  # è¿›è¡Œ ASR è½¬æ¢ / Perform ASR conversion
            if (
                asr_text == "error"
            ):  # æ£€æŸ¥ ASR ç»“æœé•¿åº¦æ˜¯å¦å°äº4ä¸ªå­—ç¬¦ / Check if ASR result length is less than 4 characters
                self.get_logger().warn(
                    "I still don't understand what you mean. Please try again"
                )

                self.play_audio(self.audio_dict[self.error_response])
            else:
                self.get_logger().info(asr_text)
                self.get_logger().info("ğŸ˜€okay, let me think for a moment...")
                self.asr_pub_result(asr_text)  # å‘å¸ƒ ASRç»“æœ / Publish ASR result
        else:
            return

    def system_sound_init(
        self,
    ):  # åˆå§‹åŒ–ç³»ç»Ÿå£°éŸ³ç›¸å…³çš„åŠŸèƒ½ / Initialize system sound functionality
       
        pkg_path = get_package_share_directory("largemodel")
        self.audio_dict = {}  # ç³»ç»Ÿå£°éŸ³å­—å…¸ / Dictionary of system sounds
        self.audio_dict["longwan-women-1"] = os.path.join(
            pkg_path, "resources_file", "longwan-women-1.mp3"
        )
        self.audio_dict["longwan-women-2"] = os.path.join(
            pkg_path, "resources_file", "longwan-women-2.mp3"
        )
        self.audio_dict["longxiaochun-women-1"] = os.path.join(
            pkg_path, "resources_file", "longxiaochun-women-1.mp3"
        )
        self.audio_dict["longxiaochun-women-2"] = os.path.join(
            pkg_path, "resources_file", "longxiaochun-women-2.mp3"
        )

    def asr_mdoel_init(self):  # åˆå§‹åŒ–asræ¨¡å‹ / Initialize ASR model
        if self.regional_setting == "international":  

            self.get_logger().info(
                f"The online asr model :XUN-FEI ASR is loaded"
            )            
        elif self.regional_setting == "China":
            if self.use_oline_asr:
                
                self.get_logger().info(
                    f"The online asr model :{self.modelinterface.init_oline_asr(self.language)} is loaded"
                )
            else:
                # -------- SenseVoiceSmall è¯­éŸ³è¯†åˆ«  --æ¨¡å‹åŠ è½½----- / Load SenseVoiceSmall online ASR model
                self.modelinterface.init_local_asr_model()
                self.get_logger().info("The asr model :SenseVoiceSmall is loaded")        

        else:
            while True:
                self.get_logger().info()(
                    'Please check the regional_setting parameter in yahboom.yaml file, it should be either "China" or "international".'
                )
                time.sleep(1)

            
    def language_init(self):
        if self.language == "zh":
            self.first_response = "longwan-women-1"
            self.error_response = "longwan-women-2"
        elif self.language == "en":
            self.first_response = "longxiaochun-women-1"
            self.error_response = "longxiaochun-women-2"
        else:
            while True:
                self.get_logger().error(
                    "language setting error,please check your language setting"
                )  # è¯­è¨€è®¾ç½®é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¯­è¨€è®¾ç½® / Language setting error, please check your language setting
                time.sleep(3)

    def kws_init(
        self,
    ):  # åˆå§‹åŒ–å…³é”®è¯å”¤é†’ç›¸å…³çš„å†…å®¹ / Initialize keyword spotting (KWS) related content
        self.port_name = self.mic_serial_port
        self.audio_request_queue = (
            queue.Queue()
        )  # ç”¨äºä¼ é€’éŸ³é¢‘è¯·æ±‚ / Queue for passing audio requests
        self.serial_port = kws_mic(
            port=self.port_name, kwsquence=self.audio_request_queue, baudrate=115200
        )
        self.serial_port.open()
        if not self.serial_port.ser or not self.serial_port.ser.is_open:
            while True:
                time.sleep(1)
                self.get_logger().error(
                    "Failed to open kws serial port.Please check whether the hardware wiring or the voice module is normal?"
                )  # æœªèƒ½æ‰“å¼€kwsä¸²å£ / Failed to open KWS serial port
        receive_thread = threading.Thread(target=self.serial_port.receive_data)
        receive_thread.daemon = True
        receive_thread.start()

    def asr_pub_result(self, asr_result: str) -> None:
        msg = String(data=asr_result)
        self.asr_pub.publish(msg)

    def ASR_conversion(self, input_file: str) -> str:
        if self.regional_setting == "international":  
            res=rec_wav_music_en()
            if res is not None:
                return res
            else:
                return "error"
        else:
  
            if self.use_oline_asr:
                result = self.modelinterface.oline_asr(input_file)
                if result[0] == "ok" and len(result[1]) > 4:
                    return result[1]
                else:
                    self.get_logger().error(f"ASR Error:{result[1]}")  # ASRé”™è¯¯ / ASR error
                    return "error"
            else:
                result = self.modelinterface.SenseVoiceSmall_ASR(input_file)
                if result[0] == "ok" and len(result[1]) > 4:
                    return result[1]
                else:
                    self.get_logger().error(f"ASR Error:{result[1]}")  # ASRé”™è¯¯ / ASR error
                    return "error"

    def listen_for_speech(self, mic_index=0):
        self.record_status_pub.publish(Bool(data=True))
        p = pyaudio.PyAudio()
        audio_buffer = []
        silence_counter = 0
        MAX_SILENCE_FRAMES = 90  # 30å¸§*30ms=900msé™éŸ³ååœæ­¢ / Stop after 900ms of silence (30 frames * 30ms)
        speaking = False  # è¯­éŸ³æ´»åŠ¨æ ‡å¿— / Flag indicating speech activity
        frame_counter = 0  # è®¡æ•°å™¨ / Frame counter
        stream_kwargs = {
            "format": pyaudio.paInt16,
            "channels": 1,
            "rate": self.sample_rate,
            "input": True,
            "frames_per_buffer": self.frame_bytes,
        }
        if mic_index != 0:
            stream_kwargs["input_device_index"] = mic_index

        # é€šè¿‡èœ‚é¸£å™¨æç¤ºç”¨æˆ·è®²è¯ / Prompt the user to speak via the buzzer
        self.pub_beep.publish(UInt16(data=1))
        time.sleep(0.5)
        self.pub_beep.publish(UInt16(data=0))

        try:
            # æ‰“å¼€éŸ³é¢‘æµ / Open audio stream
            stream = p.open(**stream_kwargs)
            while True:
                if self.stop_event.is_set():
                    return False

                frame = stream.read(
                    self.frame_bytes, exception_on_overflow=False
                )  # è¯»å–éŸ³é¢‘æ•°æ® / Read audio data
                is_speech = self.vad.is_speech(
                    frame, self.sample_rate
                )  # VADæ£€æµ‹ / VAD detection

                if is_speech:
                    # æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨ / Detected speech activity
                    speaking = True
                    audio_buffer.append(frame)
                    silence_counter = 0
                else:
                    if speaking:
                        # åœ¨è¯­éŸ³æ´»åŠ¨åæ£€æµ‹é™éŸ³ / Detect silence after speech activity
                        silence_counter += 1
                        audio_buffer.append(
                            frame
                        )  # æŒç»­è®°å½•ç¼“å†² / Continue recording buffer

                        # é™éŸ³æŒç»­æ—¶é—´è¾¾æ ‡æ—¶ç»“æŸå½•éŸ³ / End recording when silence duration meets the threshold
                        if silence_counter >= MAX_SILENCE_FRAMES:
                            break
                frame_counter += 1
                if frame_counter % 2 == 0:
                    self.get_logger().info("1" if is_speech else "-")
                    # print('1-' if is_speech else '0-', end='', flush=True)  # å®æ—¶çŠ¶æ€æ˜¾ç¤ºæ–¹å¼ / Real-time status display
        finally:
            stream.stop_stream()
            stream.close()
            p.terminate()
            self.record_status_pub.publish(Bool(data=False))

		
        # ä¿å­˜æœ‰æ•ˆå½•éŸ³ï¼ˆå»é™¤å°¾éƒ¨é™éŸ³ï¼‰ / Save valid recording (remove trailing silence)
        if speaking and len(audio_buffer) > 0:
            # è£å‰ªæœ€åé™éŸ³éƒ¨åˆ† / Trim the last silent part
            clean_buffer = (
                audio_buffer[:-MAX_SILENCE_FRAMES]
                if len(audio_buffer) > MAX_SILENCE_FRAMES
                else audio_buffer
            )

            with wave.open(self.user_speechdir, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
                wf.setframerate(self.sample_rate)
                wf.writeframes(b"".join(clean_buffer))
                return True
				
    def play_audio(self, file_path: str) -> None:
        """
        åŒæ­¥æ–¹å¼æ’­æ”¾éŸ³é¢‘å‡½æ•°The function for playing audio in synchronous mode
        """
        while True:
            try:
                pygame.mixer.init(frequency=44100, size=-16, channels=2, buffer=512)
                break  # åˆå§‹åŒ–æˆåŠŸï¼Œè·³å‡ºå¾ªç¯
            except pygame.error as e:
                if "Device or resource busy" in str(e):
                    self.get_logger().warn("Audio device is busy, waiting...")
                    time.sleep(0.5)  # ç­‰å¾…è®¾å¤‡é‡Šæ”¾
                else:
                    self.get_logger().error(f"Unexpected audio error: {e}")
                    return  # éèµ„æºå ç”¨é”™è¯¯ï¼Œç›´æ¥è¿”å›
                
        #pygame.mixer.init(frequency=44100, size=-16, channels=2, buffer=512)
        pygame.mixer.music.load(file_path)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)
        pygame.mixer.quit()


def main(args=None):
    rclpy.init(args=args)
    sense_voice_node = ASRNode()
    try:
        sense_voice_node.main_loop()
    except KeyboardInterrupt:
        pass
    finally:
        sense_voice_node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()
